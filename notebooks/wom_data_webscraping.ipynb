{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a262de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import urllib3\n",
    "import certifi \n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d1943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: to scrape English speeches \n",
    "\n",
    "# silence warnings\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# common headers & session\n",
    "headers = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/117.0 Safari/537.36\"\n",
    "    )\n",
    "}\n",
    "\n",
    "def f_scrape_tr_speech(listing_path, total_pages=18, pause=1.0):\n",
    "    session = requests.Session()\n",
    "    session.verify = certifi.where()\n",
    "    all_records = []\n",
    "\n",
    "    # regex to filter out phone calls / visits\n",
    "    reg_pattern = re.compile(r\"\\bvisit\\b|\\bphone call(s)?\\b\", flags=re.IGNORECASE)\n",
    "\n",
    "    for page_num in range(1, total_pages + 1):\n",
    "        url = base_url + listing_path if page_num == 1 else f\"{base_url}{listing_path}?&page={page_num}\"\n",
    "        print(f\"Scraping page {page_num} â†’ {url}\")\n",
    "\n",
    "        resp = session.get(url, headers=headers, timeout=10, verify=False)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "\n",
    "        for dt in soup.find_all(\"dt\", class_=\"date\"):\n",
    "            date_str = dt.get_text(strip=True)\n",
    "            dd = dt.find_next_sibling(\"dd\")\n",
    "            a = dd.find(\"a\")\n",
    "            href = a[\"href\"]\n",
    "            full_url = base_url + href\n",
    "            title = a.get_text(strip=True)\n",
    "\n",
    "            # skip titles mentioning visits or phone calls\n",
    "            if reg_pattern.search(title):\n",
    "                continue\n",
    "\n",
    "            # Fetch the detail page\n",
    "            art_resp = session.get(full_url, headers=headers, timeout=10, verify=False)\n",
    "            art_resp.raise_for_status()\n",
    "            art_soup = BeautifulSoup(art_resp.content, \"html.parser\")\n",
    "\n",
    "            content_div = (\n",
    "                art_soup.find(id=\"divContentArea\")\n",
    "                or art_soup.select_one(\"div.field--name-body\")\n",
    "                or art_soup.find(\"article\")\n",
    "            )\n",
    "            if not content_div:\n",
    "                continue\n",
    "\n",
    "            # Extract and clean paragraphs\n",
    "            paras = [p.get_text(strip=True) for p in content_div.find_all(\"p\")]\n",
    "            # drop fragments that end with comma (greetings)\n",
    "            paras = [t for t in paras if t and not t.endswith(',')]\n",
    "\n",
    "            # remove paragraphs with fewer than 4 words\n",
    "            paras = [t for t in paras if len(t.split()) >= 4]\n",
    "\n",
    "            if not paras:\n",
    "                continue\n",
    "\n",
    "            for paragraph in paras:\n",
    "                all_records.append({\n",
    "                    \"date\":  date_str,\n",
    "                    \"link\":  full_url,\n",
    "                    \"title\": title,\n",
    "                    \"text\":  paragraph\n",
    "                })\n",
    "\n",
    "            time.sleep(pause)\n",
    "\n",
    "    return pd.DataFrame(all_records, columns=[\"date\", \"link\", \"title\", \"text\"])\n",
    "\n",
    "\n",
    "# Turkey Articles in English \n",
    "base_url = \"https://www.tccb.gov.tr\"\n",
    "df_tr_speech_en = f_scrape_tr_speech(\"/en/receptayyiperdogan/speeches/\")\n",
    "\n",
    "# Save the data to CSV ()\n",
    "#df_tr_speech_en.to_csv(\"../data/raw/tr_speech_en.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
